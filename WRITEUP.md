# Project Write-Up

## Explaining Custom Layers

The models which are imported might have custom layers whose exact replica is not present in openvino. The process behind converting custom layers involves registering the layers as Custom, then use Caffe to calculate the output shape of the layer. We need Caffe on your system to do this option.

If not handled, custom layers are not able to infer and is listed under unsupported layers. To avoid this from happening, its important that we convert the custom layers

## Comparing Model Performance

In order to compare the model, I planned on to comparing them on the basis of three factors
1. size of the model
2. Inference time of the model
3. Counting accuracy of the model or Atleast drawing correct number of boxes

| Model Name                   | Size after conversion (.bin file) | Boxes Detected            | Inference Time | Accuracy                                                     |
| ---------------------------- | --------------------------------- | ------------------------- | -------------- | ------------------------------------------------------------ |
| MobileNet-SSD V2             | 65 MB                             | Single box detection      | ~ 70 ms        | Varied on the basis of confidence thresold.<br />Maximum 39<br />Minimum 11 |
| ssd_v2 inception             | 95 MB                             | Multiple Objects detected | ~1 s           | Inference time too high                                      |
| Yolo V3                      | 236 MB                            | Multiple Objects detected | ~1 s           | Inference time too high                                      |
| person-detection-retail-0013 | 1 MB                              | Single box detection      | ~ 42 ms        | 6 people detected                                            |

## Assess Model Use Cases

This framework can be used for alot of use cases and why it will be useful :-
### Counting number of people entering or leaving a store to determine the peak hours.
The app can be used to omonitor the foot fall in a store, where the camera can be placed at the enterance and we can calculate the number of people who entered the store. Once we have such statistics, we can leverage it by deciding when to have more staffs in the store, what are the peak hours, etc.
### Alarming the security in case someone is trying to trespass an area.
Trespassing a prohibited area is a problem and using the person detection technique, we can combat that. For example, we can monitor forests and know when a poacher enters the area. We can also determine the heavily poached segments of a forest using the same idea of count number of people. Using this, we can save the animals from getting poached by increasing the security in heavily poached areas.

## Assess Effects on End User Needs

Lighting, model accuracy, and camera focal length/image size have different effects on a
deployed edge model. The potential effects of each of these are as follows...

1. If the lighting is not proper, the detection becomes difficult and hence provides incorrect results. 
2. Decrease in model accuracy can lead to miscounting which will lead to wrong statistics. 
3. If the focal length/ image size is very skewed, the detection becomes difficult as the image of human in frame might not be captured nicely.

## Model Research

In investigating potential people counter models, I tried each of the following three models:

- Model 1: [MobileNet-SSD V2]
  - [http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz]
  
  - I converted the model to an Intermediate Representation with the following steps...
    Step 1 - wget `"http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz"`
    Step 2 - `tar -xvf ssd_mobilenet_v2_coco_2018_03_29.tar.gz` to extract pipeline config and `.pb` file
    Step 3 - Convert to IR format. I used following snippet for succesful conversion 
    `"python /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py --input_model frozen_inference_graph.pb --tensorflow_object_detection_api_pipeline_config pipeline.config --reverse_input_channels --tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json "`
  
    
  
  - The model was insufficient for the app because...
  1. The inference time of the model was slightly more ~ 70ms 
  2. The model was not able to hold upto its detection for long. The boxes generated by the model flickered alot due to which both total count and duration was getting sacrificed. 
  3. To improve the model I tried different prob_threshold like 0.1,0.3,0.7,0.9 . The lower thresholds were generating the boxes very confidentally but was counting other objects as well and the higher confidence acually increased the flickering issue.
  
- Model 2: [ssd_v2 inception]
  - [http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz]
  - I converted the model to an Intermediate Representation with the following steps...
  Step 1 - wget `"http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz"`
  Step 2 - `tar -xvf ssd_inception_v2_coco_2018_01_28.tar.gz` to extract pipeline config and `.pb` file
  Step 3 - Convert to IR format. I used following snippet for succesful conversion 
  `"python /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py --input_model frozen_inference_graph.pb --tensorflow_object_detection_api_pipeline_config pipeline.config --reverse_input_channels --tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json "`
  
  
  - The model was insufficient for the app because...
  1. The inference time of the model was very high it was nearly 1s 
  2. The model was generating too many boxes which led to false detection. I think it was trying to detect other objects as well apart from person.

- Model 3: [Yolo V3]
  - [https://github.com/mystic123/tensorflow-yolo-v3]
  - I converted the model to an Intermediate Representation with the following arguments...
  Step 1 :- obtained the weights and coco.names file from 
  1. Download COCO class names file: `wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names`
2. Download and convert model weights:    
    1. Download binary file with desired weights: 
        1. Full weights: `wget https://pjreddie.com/media/files/yolov3.weights`
    Step 2 - Used `python3 convert_weights_pb.py --class_names coco.names --data_format NHWC --weights_file yolov3.weights` to obtain `frozen_darknet_yolov3_model.pb` file
    Step 3 - Converted the `frozen_darknet_yolov3_model.pb` file to `.xml` and `.bin` using `python /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py --input_model frozen_darknet_yolov3_model.pb --tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/yolo_v3.json -b 1`
  - The model was insufficient for the app because...
    Inference time was in order of ~1000ms even after using OpenVino
  - I tried to improve the model for the app by...
    using yolo tiny version but still the inference time was high.


## Final Model and app

To ensure the desired output for people count and less inferencing time, I used OpenVINO's pre-trained and preconverted `FP16` version of `person-detection-retail-0013.xml`. 
To Obtain this model, I used the download mechanism explained in `Leveraging Pre-trained model` module. 
`sudo ./downloader.py --name person-detection-retail-0013 -o /home/workspace`
The above command downloaded all the precisions. But only FP16 was used by me. 

In order to run the app, you should use

`python main.py -i resources/Pedestrian_Detect_2_1_1.mp4 -m path_to_your_model -l /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_sse4.so -d CPU -pt 0.6 | ffmpeg -v warning -f rawvideo -pixel_format bgr24 -video_size 768x432 -framerate 24 -i - http://0.0.0.0:3004/fac.ffm`